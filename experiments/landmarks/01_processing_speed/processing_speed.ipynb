{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:30:31.484294Z",
     "start_time": "2025-11-12T13:30:31.434138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "50d99727299ac408",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data processing notebook\n",
    "\n",
    "Quiero armar un pipeline basico que pase los videos por mediapipe, y los guarde junto a sus labels.\n",
    "Por ahora solo quiero extraer la info de manos y cuerpo y normalizar las coordenadas"
   ],
   "id": "8f5bfd8136e7ba47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:35:33.464627Z",
     "start_time": "2025-11-12T13:35:33.388909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Time test between mediapipe pose + mediapipe hands vs mediapipe holistic\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from src.utils.video import frame_reader\n",
    "cap = cv2.VideoCapture(\"../../../data/LSA64/video/001_001_001.mp4\")"
   ],
   "id": "c05001b49838805f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:30:48.721102Z",
     "start_time": "2025-11-12T13:30:42.187902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "with mp.solutions.pose.Pose() as pose, mp.solutions.hands.Hands(max_num_hands=2) as hands:\n",
    "    for frame in frame_reader(cap):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pose_results = pose.process(rgb)\n",
    "        hands_results = hands.process(rgb)"
   ],
   "id": "1c6b220e09f7e433",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762954242.254261  116989 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1762954242.256754  117129 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.2.3-arch1.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1762954242.261615  116989 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1762954242.263029  117144 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.2.3-arch1.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "W0000 00:00:1762954242.280004  117133 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954242.297388  117130 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954242.316761  117116 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954242.342867  117118 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954242.369699  117118 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.68 s, sys: 679 ms, total: 8.36 s\n",
      "Wall time: 6.51 s\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T12:41:14.142677Z",
     "start_time": "2025-11-12T12:41:08.797781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "with mp.solutions.holistic.Holistic() as pose:\n",
    "        for frame in frame_reader(cap):\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pose_results = pose.process(rgb)"
   ],
   "id": "9c2ca8b17d790cc7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762951268.829084   89390 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1762951268.831084  108614 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.2.3-arch1.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "W0000 00:00:1762951268.871498  108601 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762951268.885419  108602 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762951268.887774  108601 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762951268.887970  108600 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762951268.887985  108610 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762951268.895608  108607 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762951268.896273  108603 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762951268.896783  108610 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.91 s, sys: 651 ms, total: 9.56 s\n",
      "Wall time: 5.33 s\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:34:01.651204Z",
     "start_time": "2025-11-12T13:34:01.586827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ahora probar hacer multithreading con hands y pose. Mediapipe usa C++ asi que no tiene el GIL\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ],
   "id": "9e587b3b74f2cb4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:34:05.915607Z",
     "start_time": "2025-11-12T13:34:02.126554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "with mp.solutions.pose.Pose() as pose, mp.solutions.hands.Hands(max_num_hands=2) as hands, \\\n",
    "     ThreadPoolExecutor(max_workers=2) as ex:\n",
    "\n",
    "    for frame in frame_reader(cap):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        fut_pose  = ex.submit(pose.process, rgb)\n",
    "        fut_hands = ex.submit(hands.process, rgb)\n",
    "\n",
    "        pose_results  = fut_pose.result()\n",
    "        hands_results = fut_hands.result()"
   ],
   "id": "a380d261f814f99d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762954442.191540  116989 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1762954442.197062  117755 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.2.3-arch1.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "I0000 00:00:1762954442.218264  116989 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1762954442.223498  117770 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.2.3-arch1.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "W0000 00:00:1762954442.251296  117758 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954442.270012  117762 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954442.296112  117742 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954442.340450  117745 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.09 s, sys: 726 ms, total: 7.81 s\n",
      "Wall time: 3.74 s\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exploracion\n",
    "\n",
    "Ahora quiero probar si mediapipe llega a capturar las 2 manos o si voy a tener que hacer algo raro para recuperar datos perdidos"
   ],
   "id": "affb5068708335f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:37:52.926333Z",
     "start_time": "2025-11-12T13:37:50.415432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.mediapipe.render import render_frame\n",
    "\n",
    "with mp.solutions.pose.Pose() as pose, mp.solutions.hands.Hands(max_num_hands=2) as hands, \\\n",
    "     ThreadPoolExecutor(max_workers=2) as ex:\n",
    "\n",
    "    for frame in frame_reader(cap, fps=12):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        fut_pose  = ex.submit(pose.process, rgb)\n",
    "        fut_hands = ex.submit(hands.process, rgb)\n",
    "\n",
    "        pose_results  = fut_pose.result()\n",
    "        hands_results = fut_hands.result()\n",
    "\n",
    "        render_frame(frame, pose_results, hands_results)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "aa5dec23eddfecd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762954670.482547  116989 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1762954670.488477  118830 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.2.3-arch1.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "I0000 00:00:1762954670.501894  116989 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1762954670.504645  118845 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.2.3-arch1.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "W0000 00:00:1762954670.527625  118832 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954670.538709  118834 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954670.564975  118816 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762954670.584898  118818 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Resultados\n",
    "Tenia 2 opciones, usar:\n",
    "1. Mediapipe holistic e ignorar todos los puntos de la cara\n",
    "2. Mediapipe ands + pose y sincronizarlos\n",
    "\n",
    "Correr mediapipe hands y pose en multithreading es un poco mas rapido que holistic, el problema es que parece capturar peor los datos de los hand landmarks, y no quiero lidiar con el lio de la sincronizacion de landmarks para solo tener un peque√±o boost de velocidad."
   ],
   "id": "c40f7105e8735cdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b888758b50d0823"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
