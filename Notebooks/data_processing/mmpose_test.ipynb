{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Objetivo\n",
    "\n",
    "Quiero probar MMPose vs Mediapipe a ver si funciona considerablemente mejor. Para eso voy a checkear el accuracy en % de frames de mano derecha vs 2 manos"
   ],
   "id": "9aeba1b608eb734e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:41:36.393543Z",
     "start_time": "2025-11-14T12:41:33.439448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import cv2\n",
    "from mmpose.apis import MMPoseInferencer\n",
    "import torch"
   ],
   "id": "2cac8fbb5c2b8e45",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:41:37.000243Z",
     "start_time": "2025-11-14T12:41:36.909012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap_rh = cv2.VideoCapture(\"../../data/LSA64/video/001_001_001.mp4\")\n",
    "cap_bh = cv2.VideoCapture(\"../../data/LSA64/video/031_001_001.mp4\")"
   ],
   "id": "a4cb73ca1330378c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:41:42.158344Z",
     "start_time": "2025-11-14T12:41:37.473169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_path = \"../../utils/landmarks/neutral_hand.png\"\n",
    "inferencer = MMPoseInferencer(\"hand\")\n",
    "result_generator = inferencer(img_path, show=True)\n",
    "result = next(result_generator)\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "4fedecf18112c7b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-m_simcc-hand5_pt-aic-coco_210e-256x256-74fb594_20230320.pth\n",
      "11/14 09:41:38 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - Failed to search registry with scope \"mmpose\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmpose\" is a correct scope, or whether the registry is initialized.\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_nano_8xb32-300e_hand-267f9c8f.pth\n",
      "11/14 09:41:39 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmpose/datasets/datasets/utils.py:102: UserWarning: The metainfo config file \"configs/_base_/datasets/onehand10k.py\" does not exist. A matched config file \"/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmpose/.mim/configs/_base_/datasets/onehand10k.py\" will be used instead.\n",
      "  warnings.warn(\n",
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmdet/apis/det_inferencer.py:154: UserWarning: palette does not exist, random is used by default. You can also set the palette to customize.\n",
      "  warnings.warn(\n",
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Qt: Session management error: Could not open network socket\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:42:29.737027Z",
     "start_time": "2025-11-14T12:41:44.370770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now try doing inference over a video(uses CPU for some reason by default)\n",
    "inferencer = MMPoseInferencer(\"hand\", device=\"cuda\")\n",
    "result_generator = inferencer(\"../../data/LSA64/video/031_001_001.mp4\", show=True)\n",
    "results = [res for res in result_generator]\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "96511f969b89253d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14 09:41:44 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - The current default scope \"mmdet\" is not \"mmpose\", `init_default_scope` will force set the currentdefault scope to \"mmpose\".\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-m_simcc-hand5_pt-aic-coco_210e-256x256-74fb594_20230320.pth\n",
      "11/14 09:41:44 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - The current default scope \"mmpose\" is not \"mmdet\", `init_default_scope` will force set the currentdefault scope to \"mmdet\".\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_nano_8xb32-300e_hand-267f9c8f.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmpose/datasets/datasets/utils.py:102: UserWarning: The metainfo config file \"configs/_base_/datasets/onehand10k.py\" does not exist. A matched config file \"/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmpose/.mim/configs/_base_/datasets/onehand10k.py\" will be used instead.\n",
      "  warnings.warn(\n",
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmdet/apis/det_inferencer.py:154: UserWarning: palette does not exist, random is used by default. You can also set the palette to customize.\n",
      "  warnings.warn(\n",
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/pipev/.conda/envs/SignTranslator/lib/python3.8/site-packages/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:06:37.512128Z",
     "start_time": "2025-11-14T12:06:37.497781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))"
   ],
   "id": "aff0aaaf293eca8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: Quadro T1000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Resultados\n",
    "\n",
    "Anda horriblemente lento y apenas captura landmarks. No se si es porque en el dataset tiene guantes el tipo, o por alguna otra razon.\n",
    "\n",
    "Por mas que seguramente hayan mejores modelos que mediapipe, va a ser tan dificil de encontrarlos y hacerlos andar que voy a demorarme mas en hacer funcionar la inferencia en landmarks que simplemente lidiar con la peque√±a perdida de datos que tendria en mediapipe."
   ],
   "id": "5c444eea544dc9c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
